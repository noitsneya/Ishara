# Ishara - Real-time Sign Language Interpreter


Ishara is a real-time sign language interpreter that converts sign language gestures into text and speech. It focuses on **Indian Sign Language (ISL)** and aims to enhance accessibility for the deaf and hard-of-hearing community.

## Features

- **Real-time Gesture Recognition**: Uses computer vision and deep learning to recognize ISL gestures.
- **Text and Speech Output**: Converts detected gestures into text and speech for seamless communication.
- **Customizable Model**: Users can train and fine-tune the model for personalized usage.
- **Lightweight and Efficient**: Optimized for real-time performance on edge devices.

## Tech Stack

- **Frontend**: Flutter
- **Programming Language**: Python
- **Machine Learning Framework**: TensorFlow 
- **Computer Vision**: OpenCV, MediaPipe
- **Backend**: Flask, Web Sockets

## Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/ishara.git
   cd ishara
   ```
2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
3. **Run the Application**:
   ```bash
   python main.py
   ```

## Usage

- Run `main.py` to start the real-time interpreter.
- Ensure your webcam is enabled for gesture detection.
- Recognized signs will be displayed as text and converted into speech.

## Contributing

We welcome contributions! Follow these steps to contribute:

1. Fork the repository.
2. Create a new branch: `git checkout -b feature-name`
3. Commit your changes: `git commit -m "Add feature-name"`
4. Push to the branch: `git push origin feature-name`
5. Open a Pull Request.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For questions or collaboration, reach out at [your email] or open an issue on GitHub.

